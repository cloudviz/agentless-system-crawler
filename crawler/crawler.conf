[ general ]
    #enabled_plugins = os_container, cpu_container
    #enabled_emitter_plugins = Stdout Emitter, File Emitter
[ crawlers ]

    [[ os_container ]]		
    target = CONTAINER		
		
    [[ process_container ]]		
		
    [[ os_vm ]]		
		
    [[ process_vm ]]		
		
    [[ os_host ]]		
		
    [[ process_host ]]		
		
    [[ ruby_pkg ]]		
    		
    [[ python_pkg ]]		
    avoid_setns = False

    [[ fprobe_container ]]
    # parameters for softflowd timeouts
    maxlife_timeout = 5

    # flow probe must create the chosen netflow version
    netflow_version = 10

    # The directory where all the flow probe's output data will be written to
    fprobe_output_dir = /tmp/crawler-fprobe

    # The filename pattern of the files that the data collector will produce
    # container-id, pid, and timestamp will be replaced with concrete values
    output_filepattern = fprobe-{ifname}-{timestamp}

    # The user to switch socket-datafile collector to in order to
    # drop root privileges
    fprobe_user = nobody

    # Terminate the started netflow probe process when terminating the crawler;
    # this is useful when running the crawler as a process and all started
    # flow probe processes should automatically terminate, thus ending to
    # produce further data; set to 'false' or '0' to disable, enable otherwise;
    # the default value is 'false'
    terminate_fprobe = 1

    # Berkel packet filter for the probe
    fprobe_bpf = (tcp[tcpflags] & (tcp-syn|tcp-ack|tcp-fin) != 0) or not tcp

    [[ ctprobe_container ]]

    # The user to switch socket-datafile collector and conntrackprobe to
    # in order to drop root privileges
    ctprobe_user = nobody

    # The directory where all the probe's output data will be written to
    ctprobe_output_dir = /tmp/crawler-ctprobe

    # The filename pattern of the files that the data collector will produce
    # container-id, pid, and timestamp will be replaced with concrete values
    output_filepattern = fprobe-{ifname}-{timestamp}

[ emitters ]

    [[ Stdout Emitter ]]
    arg_from_conf = 1
    format = csv
    
    [[ File Emitter ]]
    url = file://tmp/crawler-out
    format = csv
    arg_from_conf = 2

    [[ SAS Https Emitter ]]
    token_filepath = /etc/sas-secrets/token
    access_group_filepath = /etc/sas-secrets/access_group
    cloudoe_filepath = /etc/sas-secrets/cloudoe
    ssl_verification = False
